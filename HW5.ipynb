{"nbformat":4,"nbformat_minor":0,"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.7"},"colab":{"name":"HW5.ipynb","provenance":[],"collapsed_sections":[],"toc_visible":true},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"mPerw0uAPGbc","colab_type":"text"},"source":["# Урок 5. Рекуррентные нейронные сети\n","\n","## Практическое задание\n","\n","1. Попробуйте обучить нейронную сеть LSTM на любом другом датасете. Опишите в комментарии к уроку - какой результата вы добились от нейросети? Что помогло вам улучшить ее точность?\n","2. *Попробуйте на numpy реализовать нейронную сеть архитектуры LSTM\n","3. *Предложите свои варианты решения проблемы исчезающего градиента в RNN"]},{"cell_type":"markdown","metadata":{"id":"n0Yt8YdqPGbv","colab_type":"text"},"source":["### 1. LSTM для IMDB\n"]},{"cell_type":"code","metadata":{"id":"lp_vvy0fPGbw","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":119},"executionInfo":{"status":"ok","timestamp":1600768848900,"user_tz":-180,"elapsed":8667,"user":{"displayName":"Дмитрий Фукин","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhOgXORSMlpkMpukDZcLijzceS9AaqgT1tfLKD3jA=s64","userId":"04706038827385634385"}},"outputId":"9c31e2a3-d81f-4f3e-a20a-8aa09902e434"},"source":["from __future__ import print_function\n","\n","from keras.preprocessing import sequence\n","from keras.models import Sequential\n","from keras.layers import Dense, Embedding\n","from keras.layers import LSTM\n","from keras.datasets import imdb\n","from keras.regularizers import L1L2\n","from keras.optimizers import SGD, RMSprop, Adam\n","\n","max_features = 20000\n","maxlen = 80\n","\n","print('Загрузка данных...')\n","(x_train, y_train), (x_test, y_test) = imdb.load_data(num_words=max_features)\n","print(len(x_train), 'тренировочные последовательности')\n","print(len(x_test), 'тестовые последовательности')\n","\n","print('Pad последовательности (примеров в x единицу времени)')\n","x_train = sequence.pad_sequences(x_train, maxlen=maxlen)\n","x_test = sequence.pad_sequences(x_test, maxlen=maxlen)\n","print('x_train shape:', x_train.shape)\n","print('x_test shape:', x_test.shape)"],"execution_count":1,"outputs":[{"output_type":"stream","text":["Загрузка данных...\n","25000 тренировочные последовательности\n","25000 тестовые последовательности\n","Pad последовательности (примеров в x единицу времени)\n","x_train shape: (25000, 80)\n","x_test shape: (25000, 80)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"9ClNa8C44uvS","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":85},"executionInfo":{"status":"ok","timestamp":1600768929228,"user_tz":-180,"elapsed":88983,"user":{"displayName":"Дмитрий Фукин","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhOgXORSMlpkMpukDZcLijzceS9AaqgT1tfLKD3jA=s64","userId":"04706038827385634385"}},"outputId":"c4b4e492-ebe1-43f0-bdeb-16dc87229d06"},"source":["print('Построение модели...')\n","model = Sequential()\n","\n","model.add(Embedding(max_features, 128))\n","model.add(LSTM(\n","    64, \n","    dropout=0.2, \n","    bias_regularizer=L1L2(0.01, 0.01)))  # L1L2(0, 0.01)\n","\n","model.add(Dense(1, activation='sigmoid'))\n","\n","model.compile(loss='binary_crossentropy',\n","              optimizer='adam',  # SGD(learning_rate=0.01, momentum=0.9),\n","              metrics=['accuracy'])\n","\n","print('Процесс обучения...')\n","model.fit(x_train, y_train,\n","          batch_size=16,\n","          epochs=1,\n","          validation_data=(x_test, y_test))"],"execution_count":2,"outputs":[{"output_type":"stream","text":["Построение модели...\n","Процесс обучения...\n","1563/1563 [==============================] - 76s 49ms/step - loss: 0.8557 - accuracy: 0.8019 - val_loss: 0.3846 - val_accuracy: 0.8417\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/plain":["<tensorflow.python.keras.callbacks.History at 0x7f47847f1fd0>"]},"metadata":{"tags":[]},"execution_count":2}]},{"cell_type":"markdown","metadata":{"id":"29gf1AEOIOcT","colab_type":"text"},"source":["Модель немного улучшилась, благодаря добавлению двойной регуляризации, так как, заметил, что модель сильно переобучалась.\n","Также пробовал менять коэффициент Dropout, что не привело к улучшению модели.\n","Аналогично другие оптимизаторы не привели к улучшению. Лучше работает Adam с дефолтными парамтерами в данной ситуации. "]},{"cell_type":"markdown","metadata":{"id":"cS3SYeExPGb0","colab_type":"text"},"source":["### 2. Генерация текста на основе книги Алисы в стране чудес"]},{"cell_type":"code","metadata":{"id":"9h6sMPC2PGb1","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"status":"ok","timestamp":1600769348445,"user_tz":-180,"elapsed":508192,"user":{"displayName":"Дмитрий Фукин","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhOgXORSMlpkMpukDZcLijzceS9AaqgT1tfLKD3jA=s64","userId":"04706038827385634385"}},"outputId":"af21fcc4-9225-49f0-fd6a-7282b7e88323"},"source":["import numpy as np\n","from keras.layers import Dense, Activation\n","from keras.layers.recurrent import SimpleRNN, LSTM, GRU\n","from keras.models import Sequential\n","\n","\n","# построчное чтение из примера с текстом \n","with open(\"alice_in_wonderland.txt\", 'rb') as _in:\n","    lines = []\n","    for line in _in:\n","        line = line.strip().lower().decode(\"ascii\", \"ignore\")\n","        if len(line) == 0:\n","            continue\n","        lines.append(line)\n","text = \" \".join(lines)\n","chars = set([c for c in text])\n","nb_chars = len(chars)\n","\n","\n","# создание индекса символов и reverse mapping чтобы передвигаться между значениями numerical\n","# ID and a specific character. The numerical ID will correspond to a column\n","# ID и определенный символ. Numerical ID будет соответсвовать колонке\n","# число при использовании one-hot кодировки для представление входов символов\n","char2index = {c: i for i, c in enumerate(chars)}\n","index2char = {i: c for i, c in enumerate(chars)}\n","\n","# для удобства выберете фиксированную длину последовательность 10 символов \n","SEQLEN, STEP = 10, 1\n","input_chars, label_chars = [], []\n","\n","# конвертация data в серии разных SEQLEN-length субпоследовательностей\n","for i in range(0, len(text) - SEQLEN, STEP):\n","    input_chars.append(text[i: i + SEQLEN])\n","    label_chars.append(text[i + SEQLEN])\n","\n","\n","# Вычисление one-hot encoding входных последовательностей X и следующего символа (the label) y\n","\n","X = np.zeros((len(input_chars), SEQLEN, nb_chars), dtype=np.bool)\n","y = np.zeros((len(input_chars), nb_chars), dtype=np.bool)\n","for i, input_char in enumerate(input_chars):\n","    for j, ch in enumerate(input_char):\n","        X[i, j, char2index[ch]] = 1\n","    y[i, char2index[label_chars[i]]] = 1\n","\n","\n","# установка ряда метапамертров  для нейронной сети и процесса тренировки\n","BATCH_SIZE, HIDDEN_SIZE = 128, 128\n","NUM_ITERATIONS = 25\n","NUM_EPOCHS_PER_ITERATION = 1\n","NUM_PREDS_PER_EPOCH = 100\n","\n","\n","# Create a super simple recurrent neural network. There is one recurrent\n","# layer that produces an embedding of size HIDDEN_SIZE from the one-hot\n","# encoded input layer. This is followed by a Dense fully-connected layer\n","# across the set of possible next characters, which is converted to a\n","# probability score via a standard softmax activation with a multi-class\n","# cross-entropy loss function linking the prediction to the one-hot\n","# encoding character label.\n","\n","'''\n","Создание очень простой рекуррентной нейронной сети. В ней будет один реккурентный закодированный входной слой. За ним последует полносвязный слой связанный с набором возможных следующих символов, которые конвертированы в вероятностные результаты через стандартную softmax активацию с multi-class cross-encoding loss функцию ссылающуются на предсказание one-hot encoding лейбл символа\n","'''\n","\n","model = Sequential()\n","model.add(\n","    LSTM(\n","        HIDDEN_SIZE,\n","        return_sequences=False,\n","        input_shape=(SEQLEN, nb_chars),\n","        dropout=0.1, \n","        bias_regularizer=L1L2(0.01, 0.01),\n","        unroll=True\n","    )\n",")\n","model.add(Dense(nb_chars))\n","model.add(Activation(\"softmax\"))\n","model.compile(loss=\"categorical_crossentropy\", optimizer=\"rmsprop\")\n","\n","\n","# выполнение серий тренировочных и демонстрационных итераций \n","for iteration in range(NUM_ITERATIONS):\n","\n","    # для каждой итерации запуск передачи данных в модель \n","    print(\"=\" * 50)\n","    print(\"Итерация #: %d\" % (iteration))\n","    model.fit(\n","        X, \n","        y, \n","        batch_size=BATCH_SIZE, \n","        epochs=NUM_EPOCHS_PER_ITERATION)\n","\n","    # Select a random example input sequence.\n","    test_idx = np.random.randint(len(input_chars))\n","    test_chars = input_chars[test_idx]\n","\n","    # для числа шагов предсказаний использование текущей тренируемой модели \n","    # конструирование one-hot encoding для тестирования input и добавление предсказания.\n","    print(\"Генерация из посева: %s\" % (test_chars))\n","    print(test_chars, end=\"\")\n","    for i in range(NUM_PREDS_PER_EPOCH):\n","\n","        # здесь one-hot encoding.\n","        X_test = np.zeros((1, SEQLEN, nb_chars))\n","        for j, ch in enumerate(test_chars):\n","            X_test[0, j, char2index[ch]] = 1\n","\n","        # осуществление предсказания с помощью текущей модели.\n","        pred = model.predict(X_test, verbose=0)[0]\n","        y_pred = index2char[np.argmax(pred)]\n","\n","        # вывод предсказания добавленного к тестовому примеру \n","        print(y_pred, end=\"\")\n","\n","        # инкрементация тестового примера содержащего предсказание\n","        test_chars = test_chars[1:] + y_pred\n","print()\n"],"execution_count":3,"outputs":[{"output_type":"stream","text":["WARNING:tensorflow:Layer lstm_1 will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n","==================================================\n","Итерация #: 0\n","1241/1241 [==============================] - 12s 10ms/step - loss: 3.3531\n","Генерация из посева: f the proj\n","f the projent the sout the sout the sout the sout the sout the sout the sout the sout the sout the sout the so==================================================\n","Итерация #: 1\n","1241/1241 [==============================] - 12s 10ms/step - loss: 2.1363\n","Генерация из посева: his time, \n","his time, and the groped the said the wast the groped the said the wast the groped the said the wast the grope==================================================\n","Итерация #: 2\n","1241/1241 [==============================] - 12s 10ms/step - loss: 1.9709\n","Генерация из посева:  ive read \n"," ive read the dore the dore the dore the dore the dore the dore the dore the dore the dore the dore the dore t==================================================\n","Итерация #: 3\n","1241/1241 [==============================] - 12s 10ms/step - loss: 1.8649\n","Генерация из посева: ear! oh de\n","ear! oh der and the mork to the was her said the mork to the was her said the mork to the was her said the mor==================================================\n","Итерация #: 4\n","1241/1241 [==============================] - 12s 10ms/step - loss: 1.7914\n","Генерация из посева: y; and thi\n","y; and thing the dory with the gryphon was the dormouse the gryphon was the dormouse the gryphon was the dormo==================================================\n","Итерация #: 5\n","1241/1241 [==============================] - 12s 10ms/step - loss: 1.7310\n","Генерация из посева: ess, and t\n","ess, and the morse the mork turtle said the more the morse the mork turtle said the more the morse the mork tu==================================================\n","Итерация #: 6\n","1241/1241 [==============================] - 12s 10ms/step - loss: 1.6839\n","Генерация из посева: the knave.\n","the knave. the mores of the project gutenberg-tm with the thing the project gutenberg-tm with the thing the pr==================================================\n","Итерация #: 7\n","1241/1241 [==============================] - 12s 10ms/step - loss: 1.6442\n","Генерация из посева: home? when\n","home? when she was a little thing as she cauld the mock turtle said the king as she cauld the mock turtle said==================================================\n","Итерация #: 8\n","1241/1241 [==============================] - 12s 10ms/step - loss: 1.6102\n","Генерация из посева: t in large\n","t in large the dormouse the dormouse the dormouse the dormouse the dormouse the dormouse the dormouse the dorm==================================================\n","Итерация #: 9\n","1241/1241 [==============================] - 12s 10ms/step - loss: 1.5832\n","Генерация из посева: rning to a\n","rning to alice to the thing was the poor on the poor on the poor on the poor on the poor on the poor on the po==================================================\n","Итерация #: 10\n","1241/1241 [==============================] - 12s 10ms/step - loss: 1.5570\n","Генерация из посева: ted: unimp\n","ted: unimplain the mock turtle of the seet to herself to the thing was to the thing was to the thing was to th==================================================\n","Итерация #: 11\n","1241/1241 [==============================] - 12s 10ms/step - loss: 1.5372\n","Генерация из посева: gutenberg.\n","gutenberg.or which the gryphon went on in the words and she was not the beginning to the white rabbit was not ==================================================\n","Итерация #: 12\n","1241/1241 [==============================] - 12s 10ms/step - loss: 1.5167\n","Генерация из посева: alice, she\n","alice, she was a little sounded to the parther with the project gutenberg-tm license to the parther with the p==================================================\n","Итерация #: 13\n","1241/1241 [==============================] - 12s 10ms/step - loss: 1.5001\n","Генерация из посева: d her back\n","d her back to the table said to the table said to the table said to the table said to the table said to the ta==================================================\n","Итерация #: 14\n","1241/1241 [==============================] - 12s 10ms/step - loss: 1.4852\n","Генерация из посева: easily in \n","easily in a long of the see, and the mock turtle said to herself to her fee of the see, and the mock turtle sa==================================================\n","Итерация #: 15\n","1241/1241 [==============================] - 12s 10ms/step - loss: 1.4685\n","Генерация из посева: do so. sha\n","do so. shall she was not a mouse the caterpillar. i dont know what i didnt time the door was to the cook turtl==================================================\n","Итерация #: 16\n","1241/1241 [==============================] - 12s 10ms/step - loss: 1.4580\n","Генерация из посева: lt that th\n","lt that the mock turtle as she could not come on the same thing as it was a court, and the mock turtle as she ==================================================\n","Итерация #: 17\n","1241/1241 [==============================] - 12s 10ms/step - loss: 1.4459\n","Генерация из посева: at you hav\n","at you have to herself to herself to herself to herself to herself to herself to herself to herself to herself==================================================\n","Итерация #: 18\n","1241/1241 [==============================] - 12s 10ms/step - loss: 1.4359\n","Генерация из посева: we were tr\n","we were tried the caterpillar the court, and the mock turtle she was not the beginning to the table was to the==================================================\n","Итерация #: 19\n","1241/1241 [==============================] - 12s 10ms/step - loss: 1.4262\n","Генерация из посева:  did you s\n"," did you see to the things and the mouse to the things and the mouse to the things and the mouse to the things==================================================\n","Итерация #: 20\n","1241/1241 [==============================] - 12s 10ms/step - loss: 1.4178\n","Генерация из посева: ats? do ca\n","ats? do can be a cause of the trees and the mock turtle and the mock turtle and the mock turtle and the mock t==================================================\n","Итерация #: 21\n","1241/1241 [==============================] - 12s 10ms/step - loss: 1.4088\n","Генерация из посева: rms of thi\n","rms of this agreement to see it was a little share a little share a little share a little share a little share==================================================\n","Итерация #: 22\n","1241/1241 [==============================] - 12s 10ms/step - loss: 1.3994\n","Генерация из посева:  defective\n"," defective of the work of a minute or two thing is the door of the work of a minute or two thing is the door o==================================================\n","Итерация #: 23\n","1241/1241 [==============================] - 12s 10ms/step - loss: 1.3935\n","Генерация из посева:  ordered. \n"," ordered. there was no here the king said to herself, and the mork turtle said to herself, and the mork turtle==================================================\n","Итерация #: 24\n","1241/1241 [==============================] - 12s 10ms/step - loss: 1.3843\n","Генерация из посева: f, wheneve\n","f, whenever and the table. i dont laie to the table. i dont laie to the table. i dont laie to the table. i don\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"JmSdISEIJmzY","colab_type":"text"},"source":["LSTM показала лучший результат. Также регуляризация и Dropout немного улучшили обучение. "]},{"cell_type":"code","metadata":{"id":"Red4dBozPeML","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1600769348451,"user_tz":-180,"elapsed":508189,"user":{"displayName":"Дмитрий Фукин","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhOgXORSMlpkMpukDZcLijzceS9AaqgT1tfLKD3jA=s64","userId":"04706038827385634385"}}},"source":[""],"execution_count":3,"outputs":[]}]}